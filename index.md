Course webpage for the NYU Spring 2025 Course Special Topics in Data Science, DS-GA 3001.003/.004 (Introduction to Computer Vision). This course is aims to cover a broad topics in computer vision, and is *not* primarily a deep learning course. We will covert topics in traditional computer vision such as camera geometry, image formation, segmentation, object recognition, classification, and detection (see [Syllabus](#Syllabus)).


### Logistics

* DS-GA 3001.003 (Lecture) \
Mondays 4:55pm-6:35pm  \
**Location**: 60 Fifth Ave, Room 150

The class will be in-person. Slides will be available after the class on this webpage. (see [Schedule](#Schedule)).

* DS-GA 3001.004 (Lab) \
Thursdays 4:55pm-5:45pm \
**Location**: Silver Center, Room 401, 31 Washington Place

The labs will be in-person. Labs will be used to cover additional materials or to work through practical exercises with the TA. 



### Instructors

<a href="https://www.di.ens.fr/~ponce/">Jean Ponce</a> (jean.ponce@ens.fr)

### TAs and Graders
Long Chen (lc3424@nyu.edu)  \
Haoxu Huang (hh2740@nyu.edu)  \
Rishav Roy (rr4577@nyu.edu)

### Office Hours
Jean Ponce: Wednesdays 2:00pm-3:00pm at **Room 300, 60 5th Ave**  \
Long Chen: Thursdays 2:00pm-3:00pm at **Room 242, 60 5th Ave**


### Grading

Four programming assignments (50% of the grade) + final project (40% of the
grade) + class participation and attendance (5%) + lab participation and attendance (5%). Deliverables should be submitted using the brightspace site and is due at the end of the day (11:59pm ET) on the dates given. There will be **no extension allowed** unless prior communication and agreements are made with the instruction team.

**Assignments (50%)** \
HW 1 (Released on 1/31, Due 2/20): Camera Calibration \
HW 2 (Released on 2/21, Due 3/13): Canny Edge Detection \  
HW 3 (Released on 3/18, Due 4/11): Weak Calibration, Essential Matrices \ 

**Final Project (40%)** \
The projects will consist of choosing a paper (or multiple relevant papers) related to the contents of the class (but not covered in class), implement the methods, and provide experiment results illustrating the method along with comparisons to related work. **Projects can be done individually or in groups of at most 3 people.**

**The project is consisted of three components:**

1. Choose a topic and write a short abstract (around 150 words). Please submit the abstract using this form by March 14th using this link.
2. An in-person presentation at the end of the semester. More details to be shared.
3. A short report (about 2 pages using CVPR Latex template) that reports the methods, data, experiment setups, results and discussions. For the choice of papers, you can refer to this list, or you can pick any computer vision paper(s) of your own choosing, subject to our approval.

**Participation and Attendance (10%)**
You are expected to attend and participate in classes and labs in person. Class attendance will count for 5% of your grade and lab attendance will count for 5% of your grade.


<a name="Syllabus"></a>
### Syllabus 
  * Introduction
  * Camera geometry and calibration
  * Image processing and edge detection
  * Radiometry and color
  * Stereo vision
  * Structure from motion and 3D models from images
  * Texture and image segmentation
  * Object recognition - historical perspective
  * CNNs for object classification and detection
  * Weakly-supervised and unsupervised approaches to image and video interpretation


### References:
We do not require purchase of any textbooks and the course will be self-contained. You may wish to consult the resources below for additional material formalization. 

* D.A. Forsyth and J. Ponce, “Computer Vision: A Modern Approach”, second edition, Pearson, 2011. (<a href="https://www.pearson.com/us/higher-education/program/Forsyth-Computer-Vision-A-Modern-Approach-2nd-Edition/PGM111082.html">Link</a>)
* R. Szeliski, “Computer Vision: Algorithms and Applications”. (<a href="http://szeliski.org/Book/">PDF</a>)
* R. Hartley and A. Zisserman, “Multiple View Geometry in Computer Vision”, Cambridge University Press, 2004. (<a href="https://www.robots.ox.ac.uk/~vgg/hzbook/">Link</a>)
* M.F. Land and D.E. Nilsson, “Animal Eyes”, Oxford University Press, 2012.
* O. Faugeras, Q.T. Luong, and T. Papadopoulo, “Geometry of Multiple Images,” MIT Press, 2001.


<a name="Schedule"></a>
### Schedule:

*Note*: This table will get populated as the semester goes. Lecture and lab slides will be posted after each session.

| Date   | Lecture  | Topic                              | Links |
|--------|---------|-----------------------------------|-------|
| 01/23  | Lecture 1 | Introduction & Logistics | [Slide](https://www.di.ens.fr/~ponce/lect1.pptx) |
| 01/27  | Lecture 2 | Introduction to Computer Vision | [Slide](https://www.di.ens.fr/~ponce/lect2.pptx) |
| 01/30  | Lecture 3 | Camera geometry and calibration | [Slide](https://www.di.ens.fr/~ponce/lect3.pptx) |
| 02/03  | Lecture 4 | Camera geometry and calibration II | [Slide](https://docs.google.com/presentation/d/1rJJDl-FF6vBfNLpssOemIQcRfWEEsrYL/edit?usp=sharing) |
| 02/06  | Lab 1 | Preview of Homework 1 | [Notes](https://drive.google.com/file/d/1VF82msNocS9qiuuPJuHTJD9VhIL9g9Ri/view?usp=sharing) |
| 02/10  | Lecture 5 | Image Processing | [Slide](https://drive.google.com/file/d/1XGB6hrCqC3PrWeDG68B7zxws1wWzLfbd/view?usp=sharing) |
| 02/13  | Lecture 6 | Canny Edge Detection | [Slide](https://docs.google.com/presentation/d/14HmQmWEkC_DEDTyaDF1nig7cKurWkZ2L/edit?usp=sharing) |
| 02/18  | Lecture 7 | Image Processing II | [Slide](https://docs.google.com/presentation/d/1WDq9yJKQ_qjDmkJOZIH91TZ5H5ewSzLS/edit?usp=sharing) |
| 02/20  | Lecture 8 | Radiometry and color | [Slide](https://docs.google.com/presentation/d/1EUgUNxO4SffPanEGIwwNuEemIGt1ZfWC/edit?usp=sharing) |
| 02/24  | Lecture 9 | Radiometry | [Slide](https://docs.google.com/presentation/d/1aVMPI_Cp0YlQMIxKcFO8_WD5YbGpgj_R/edit?usp=sharing) |
| 02/27  | Lab 2 | Preview of HW 2, NMS, RANSAC | [Jupyter](https://drive.google.com/file/d/1xkzOsUD0yxy-HwBVTa4pknqXE2_6b-x3/view?usp=sharing) |
| 03/03  | Lecture 10 | Color, Stereopsis and Two-view Geometry | [Slide](https://docs.google.com/presentation/d/1298xRWehiEaxVhUJBYZ8xW_e5bl6JNzV/edit?usp=sharing) |
| 03/06  | Lecture 11 | Stereopsis | [Slide](https://docs.google.com/presentation/d/1lbQKoMBvlsVFNubxV2lb-I27B7prvyb6/edit?usp=sharing) |
| 03/10  | Lecture 12 | Two-view geometry | [Slide](https://docs.google.com/presentation/d/1iNjI4ma3hY4Ou_CXwJU0WZGKGmMl85Uy/edit?usp=sharing) |
| 03/13  | Lecture 13 | Binocular stereopsis | [Slide](https://docs.google.com/presentation/d/1pWTALy1yYDMTJwCk6Wjnn0E1uHO3ce4M/edit?usp=sharing) |
| 03/17  | Guest Lecture | Alberto Bietti: Diffusion Models | [Slide](https://docs.google.com/presentation/d/1hqWrTcJthLtLgjjwE3QljHHHhIwv1jG56JV5fgtdJ4c/edit?usp=sharing) |
| 03/20  | Lab 3 | Preview of HW3, Intro to PyTorch | [Notebook](https://drive.google.com/file/d/1lWtfJe-2AkkfQYa5qwXlDVSlmVvjlk1W/view?usp=sharing) |
| 03/31  | Lecture 14 | Structure from motion | [Slide](https://docs.google.com/presentation/d/1MjLIL1D-3afSI7JVX9MNWOJWQeRQS8Eq/edit?usp=sharing) |
| 04/03  | Lecture 15 | Structure from motion II | [Slide](https://docs.google.com/presentation/d/1FJgyAPFOopxlySwVDN4FbluLEe6PkXmV/edit?usp=sharing) |
| 04/07  | Lecture 16 | Structure from motion III | [Slide](https://docs.google.com/presentation/d/1iytVXfXLEgrhxPFW1rJLQ3U5S8srboQ_/edit?usp=sharing) |
| 04/10  | Lecture 17 | Self Calibration | [Slide](https://docs.google.com/presentation/d/1BMRO6Nwz5puMinCePlXQFyDui9z6rSDP/edit?usp=sharing) |
| 04/14  | Lecture 18 | Multi-view | [Slide](https://docs.google.com/presentation/d/1DsQPDcLg516dcd3_mUvGjVEKxH0c7THc/edit?usp=sharing) |




### Acknowledgements
Much of the material for this course relies on the Computer Vision course given at ENS Paris by Mathieu Aubry, Karteek Alahari, Ivan Laptev, and Josef Sivic. Many of the slides are taken from James Hays, Svetlana Lazebnik, and Derek Hoeim. This page refers to <a href="https://esizikova.github.io/introCV-spring2022/">course website</a> of previous section by Elena Sizikova. Website was originally designed by Matthew Trager.